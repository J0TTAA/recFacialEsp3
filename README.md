# Sistema de Reconocimiento Facial - API REST

Sistema de reconocimiento facial que identifica si una cara pertenece al usuario espec√≠fico ("me") o no ("not_me"). El proyecto incluye un pipeline completo de entrenamiento y una API REST construida con Flask para realizar predicciones en tiempo real.

## üìã Tabla de Contenidos

- [Descripci√≥n General](#descripci√≥n-general)
- [Requisitos](#requisitos)
- [Instalaci√≥n](#instalaci√≥n)
- [Estructura del Proyecto](#estructura-del-proyecto)
- [Pipeline de Entrenamiento](#pipeline-de-entrenamiento)
- [API REST](#api-rest)
- [Configuraci√≥n](#configuraci√≥n)
- [Uso](#uso)
- [Ejemplos](#ejemplos)
- [Troubleshooting](#troubleshooting)
- [Evaluaci√≥n y Reportes](#evaluaci√≥n-y-reportes)
- [√âtica y Privacidad](#√©tica-y-privacidad)

## üìñ Descripci√≥n General

Este sistema utiliza t√©cnicas de deep learning para el reconocimiento facial:

1. **Detecci√≥n de Caras**: Usa MTCNN para detectar y recortar caras en im√°genes
2. **Generaci√≥n de Embeddings**: Utiliza InceptionResnetV1 (FaceNet) pre-entrenado en VGGFace2 para generar vectores de caracter√≠sticas de 512 dimensiones
3. **Clasificaci√≥n**: Entrena un clasificador LogisticRegression para distinguir entre "me" (usuario) y "not_me" (otros)

La API REST permite realizar predicciones en tiempo real enviando im√°genes que contengan caras.

## üîß Requisitos

### Software
- Python 3.8 o superior
- pip (gestor de paquetes de Python)

### Hardware Recomendado
- **GPU NVIDIA** (opcional pero altamente recomendado para acelerar el procesamiento)
  - CUDA 11.0 o superior
  - CuDNN 8.0 o superior
- **CPU**: Procesador multi-core (funciona pero m√°s lento)
- **RAM**: M√≠nimo 4GB, recomendado 8GB+

### Sistema Operativo
- Windows 10/11
- Linux (Ubuntu 18.04+)
- macOS (con limitaciones en GPU)

## üì¶ Instalaci√≥n

### 1. Clonar o Descargar el Proyecto

```bash
cd recFacialEsp3
```

### 2. Crear Entorno Virtual (Recomendado)

**Windows:**
```bash
python -m venv venv
venv\Scripts\activate
```

**Linux/macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

Esto instalar√°:
- `torch`: PyTorch para deep learning
- `facenet-pytorch`: Modelos pre-entrenados para reconocimiento facial
- `scikit-learn`: Machine learning (clasificaci√≥n)
- `Flask`: Framework web para la API
- `flask-cors`: Soporte CORS
- `gunicorn`: Servidor WSGI para producci√≥n
- `python-dotenv`: Manejo de variables de entorno
- `Pillow`: Procesamiento de im√°genes
- `joblib`: Serializaci√≥n de modelos
- `numpy`: Operaciones num√©ricas
- `tqdm`: Barras de progreso

### 4. Verificar Instalaci√≥n

```bash
python -c "import torch; print(f'PyTorch: {torch.__version__}'); print(f'CUDA disponible: {torch.cuda.is_available()}')"
```

## üìÅ Estructura del Proyecto

```
recFacialEsp3/
‚îú‚îÄ‚îÄ api/                          # M√≥dulo de la API
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ resources/                # Endpoints de la API
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ verify.py            # Endpoint /verify
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ health.py            # Endpoint /healthz
‚îÇ   ‚îî‚îÄ‚îÄ utils/                    # Utilidades
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py
‚îÇ       ‚îú‚îÄ‚îÄ model_loader.py       # Carga de modelos
‚îÇ       ‚îî‚îÄ‚îÄ image_processor.py    # Procesamiento de im√°genes
‚îÇ
‚îú‚îÄ‚îÄ scripts/                      # Scripts de entrenamiento
‚îÇ   ‚îú‚îÄ‚îÄ crop_faces.py            # Paso 1: Recorte de caras
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.py            # Paso 2: Generaci√≥n de embeddings
‚îÇ   ‚îî‚îÄ‚îÄ run_gunicorn.sh          # Script para producci√≥n
‚îÇ
‚îú‚îÄ‚îÄ data/                         # Datos del proyecto
‚îÇ   ‚îú‚îÄ‚îÄ me/                       # Im√°genes del usuario (YO)
‚îÇ   ‚îú‚îÄ‚îÄ not_me/                   # Im√°genes de otras personas (NO-YO)
‚îÇ   ‚îú‚îÄ‚îÄ cropped/                  # Caras recortadas (generado)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ me/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ not_me/
‚îÇ   ‚îú‚îÄ‚îÄ embeddings.npy           # Embeddings generados (generado)
‚îÇ   ‚îî‚îÄ‚îÄ labels.npy               # Etiquetas (generado)
‚îÇ
‚îú‚îÄ‚îÄ models/                       # Modelos entrenados (generado)
‚îÇ   ‚îú‚îÄ‚îÄ model.joblib             # Clasificador entrenado
‚îÇ   ‚îî‚îÄ‚îÄ scaler.joblib            # Escalador de datos
‚îÇ
‚îú‚îÄ‚îÄ reports/                      # Reportes y m√©tricas (generado)
‚îÇ   ‚îú‚îÄ‚îÄ metrics.json             # M√©tricas del modelo
‚îÇ   ‚îî‚îÄ‚îÄ confusion_matrix.png     # Matriz de confusi√≥n
‚îÇ
‚îú‚îÄ‚îÄ app.py                        # Aplicaci√≥n Flask principal
‚îú‚îÄ‚îÄ train.py                     # Script de entrenamiento
‚îú‚îÄ‚îÄ requirements.txt             # Dependencias
‚îú‚îÄ‚îÄ .env                         # Variables de entorno (crear)
‚îî‚îÄ‚îÄ README.md                    # Este archivo
```

## üöÄ Pipeline de Entrenamiento

El entrenamiento del modelo se realiza en **4 pasos secuenciales**. Aseg√∫rate de ejecutarlos en orden.

### Paso 0: Preparar Datos

Antes de comenzar, organiza tus im√°genes en la siguiente estructura:

```
data/
‚îú‚îÄ‚îÄ me/              # Im√°genes del usuario (YO)
‚îÇ   ‚îú‚îÄ‚îÄ foto1.jpg
‚îÇ   ‚îú‚îÄ‚îÄ foto2.jpg
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ not_me/          # Im√°genes de otras personas (NO-YO)
    ‚îú‚îÄ‚îÄ persona1.jpg
    ‚îú‚îÄ‚îÄ persona2.jpg
    ‚îî‚îÄ‚îÄ ...
```

**Requisitos:**
- Formatos soportados: `.jpg`, `.jpeg`, `.png` (may√∫sculas o min√∫sculas)
- M√≠nimo recomendado: 20-30 im√°genes en cada categor√≠a
- Ideal: 50+ im√°genes en cada categor√≠a para mejor precisi√≥n
- Las im√°genes pueden tener diferentes tama√±os y orientaciones

### Paso 1: Recorte de Caras (`scripts/crop_faces.py`)

Este script detecta y recorta caras de todas las im√°genes usando MTCNN.

**¬øQu√© hace?**
- Detecta caras en las im√°genes usando MTCNN
- Recorta cada cara detectada
- Redimensiona a 160x160 p√≠xeles (tama√±o requerido por FaceNet)
- Corrige la orientaci√≥n EXIF autom√°ticamente
- Guarda las caras recortadas en `data/cropped/`

**Ejecutar:**
```bash
python scripts/crop_faces.py
```

**Salida:**
- `data/cropped/me/`: Caras recortadas del usuario
- `data/cropped/not_me/`: Caras recortadas de otras personas

**Notas:**
- Si una imagen no tiene cara detectada, se omite y se registra un warning
- El proceso es m√°s r√°pido con GPU (CUDA)

### Paso 2: Generaci√≥n de Embeddings (`scripts/embeddings.py`)

Este script genera vectores de caracter√≠sticas (embeddings) de 512 dimensiones para cada cara recortada.

**¬øQu√© hace?**
- Carga el modelo InceptionResnetV1 pre-entrenado en VGGFace2
- Procesa las caras recortadas en lotes (batches) para eficiencia
- Genera embeddings de 512 dimensiones para cada cara
- Crea etiquetas paralelas (1 para "me", 0 para "not_me")

**Ejecutar:**
```bash
python scripts/embeddings.py
```

**Salida:**
- `data/embeddings.npy`: Array numpy con todos los embeddings [N, 512]
- `data/labels.npy`: Array numpy con todas las etiquetas [N]

**Notas:**
- Procesamiento por lotes (batch_size=32) acelera significativamente el proceso
- Mucho m√°s r√°pido con GPU

### Paso 3: Entrenamiento del Clasificador (`train.py`)

Este script entrena un clasificador LogisticRegression para distinguir entre "me" y "not_me".

**¬øQu√© hace?**
- Carga los embeddings y etiquetas generados
- Divide los datos en entrenamiento (80%) y validaci√≥n (20%)
- Aplica StandardScaler para normalizar los embeddings
- Entrena un LogisticRegression con `class_weight='balanced'` (importante para datos desbalanceados)
- Eval√∫a el modelo y calcula m√©tricas (Accuracy, AUC-ROC, Precision, Recall, F1-score)
- Guarda el modelo entrenado y el escalador

**Ejecutar:**
```bash
python train.py
```

**Salida:**
- `models/model.joblib`: Clasificador entrenado
- `models/scaler.joblib`: Escalador ajustado
- `reports/metrics.json`: M√©tricas del modelo en formato JSON

**M√©tricas Generadas:**
- **Accuracy**: Precisi√≥n general del modelo
- **AUC-ROC**: √Årea bajo la curva ROC (mejor para datos desbalanceados)
- **Classification Report**: Precision, Recall y F1-score para cada clase

**Par√°metros Importantes:**
- `test_size=0.2`: 20% para validaci√≥n
- `random_state=42`: Semilla para reproducibilidad
- `stratify=y`: Mantiene la proporci√≥n de clases en train/test
- `class_weight='balanced'`: Ajusta pesos para datos desbalanceados

### Paso 4: Verificaci√≥n (Opcional)

Puedes verificar que el entrenamiento fue exitoso revisando:

```bash
# Ver m√©tricas
cat reports/metrics.json

# Verificar que los modelos existen
ls models/
```

### Paso 5: Evaluaci√≥n completa

```bash
python evaluate.py
```

Genera m√©tricas actualizadas, curvas ROC/PR y `reports/evaluation_results.json`. Ejecuta este paso cada vez que reentrenes el modelo para mantener trazabilidad.

## üåê API REST

La API REST permite realizar predicciones en tiempo real enviando im√°genes que contengan caras.

### Iniciar el Servidor

**Desarrollo:**
```bash
python app.py
```

El servidor se iniciar√° en `http://0.0.0.0:5000` por defecto.

**Producci√≥n (con Gunicorn):**
```bash
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```

O usar el script:
```bash
bash scripts/run_gunicorn.sh
```

### Endpoints

#### 1. `GET /`
Informaci√≥n general de la API.

**Respuesta:**
```json
{
  "name": "Face Recognition API",
  "version": "1.0.0",
  "description": "API para reconocimiento facial...",
  "endpoints": {
    "health": "/healthz",
    "verify": "/verify"
  }
}
```

#### 2. `GET /healthz`
Verifica el estado de la API y los modelos.

**Respuesta Exitosa (200):**
```json
{
  "status": "ok"
}
```

**Respuesta de Error (503):**
```json
{
  "status": "unhealthy",
  "reason": "Models not loaded"
}
```

#### 3. `POST /verify`
Endpoint principal para verificar si una cara pertenece al usuario.

**Request:**
- **Method**: POST
- **Content-Type**: `multipart/form-data`
- **Body**: 
  - Campo `image`: Archivo de imagen (jpg, png)

**Ejemplo con cURL:**
```bash
curl -X POST http://localhost:5000/verify \
  -F "image=@ruta/a/tu/imagen.jpg"
```

**Ejemplo con Python:**
```python
import requests

url = "http://localhost:5000/verify"
files = {"image": open("imagen.jpg", "rb")}
response = requests.post(url, files=files)
print(response.json())
```

**Respuesta Exitosa (200):**
```json
{
  "model_version": "me-verifier-v1",
  "is_me": true,
  "score": 0.9234,
  "threshold": 0.75,
  "timing_ms": 245.67
}
```

**Campos de Respuesta:**
- `model_version`: Versi√≥n del modelo usado
- `is_me`: `true` si la cara pertenece al usuario, `false` si no
- `score`: Probabilidad de que sea "me" (0.0 a 1.0)
- `threshold`: Umbral usado para determinar `is_me`
- `timing_ms`: Tiempo de procesamiento en milisegundos

**Respuestas de Error:**

**400 - No se detect√≥ cara:**
```json
{
  "error": "No se detect√≥ un rostro en la imagen"
}
```

**400 - Tipo de archivo inv√°lido:**
```json
{
  "error": "Tipo de archivo no permitido. Solo image/jpeg o image/png"
}
```

**413 - Archivo demasiado grande:**
```json
{
  "error": "Archivo demasiado grande. L√≠mite: 2 MB"
}
```

**503 - Modelos no cargados:**
```json
{
  "error": "Modelos no encontrados. Aseg√∫rate de haber entrenado el modelo ejecutando 'train.py'."
}
```

## ‚öôÔ∏è Configuraci√≥n

El proyecto usa variables de entorno para configuraci√≥n. Crea un archivo `.env` en la ra√≠z del proyecto:

```env
# Rutas de modelos
MODEL_PATH=models/model.joblib
SCALER_PATH=models/scaler.joblib

# Umbral de verificaci√≥n (0.0 a 1.0)
# Score >= VERIFY_THRESHOLD -> is_me = true
VERIFY_THRESHOLD=0.75

# Tama√±o m√°ximo de archivo (MB)
MAX_CONTENT_MB=2

# Versi√≥n del modelo
MODEL_VERSION=me-verifier-v1

# Configuraci√≥n del servidor Flask
FLASK_HOST=0.0.0.0
PORT=5000
FLASK_DEBUG=False
```

**Variables Disponibles:**
- `MODEL_PATH`: Ruta al modelo clasificador (default: `models/model.joblib`)
- `SCALER_PATH`: Ruta al escalador (default: `models/scaler.joblib`)
- `VERIFY_THRESHOLD`: Umbral para determinar si es "me" (default: `0.75`)
- `MAX_CONTENT_MB`: Tama√±o m√°ximo de archivo en MB (default: `2`)
- `MODEL_VERSION`: Versi√≥n del modelo (default: `me-verifier-v1`)
- `FLASK_HOST`: Host del servidor (default: `0.0.0.0`)
- `PORT`: Puerto del servidor (default: `5000`)
- `FLASK_DEBUG`: Modo debug (default: `False`)

## üí° Uso

### Flujo Completo

1. **Preparar datos:**
   ```bash
   # Organizar im√°genes en data/me/ y data/not_me/
   ```

2. **Recortar caras:**
   ```bash
   python scripts/crop_faces.py
   ```

3. **Generar embeddings:**
   ```bash
   python scripts/embeddings.py
   ```

4. **Entrenar modelo:**
   ```bash
   python train.py
   ```

5. **Iniciar API:**
   ```bash
   python app.py
   ```

6. **Hacer predicciones:**
   ```bash
   curl -X POST http://localhost:5000/verify -F "image=@foto.jpg"
   ```

## üìù Ejemplos

### Ejemplo 1: Verificaci√≥n B√°sica

```python
import requests

# Subir imagen para verificaci√≥n
url = "http://localhost:5000/verify"
with open("mi_foto.jpg", "rb") as f:
    files = {"image": f}
    response = requests.post(url, files=files)
    
result = response.json()
print(f"¬øEs mi cara? {result['is_me']}")
print(f"Score: {result['score']:.2%}")
print(f"Tiempo: {result['timing_ms']}ms")
```

### Ejemplo 2: Verificaci√≥n con Threshold Personalizado

```python
import requests
import os

# Configurar threshold en .env o directamente
os.environ["VERIFY_THRESHOLD"] = "0.8"

# Hacer verificaci√≥n
url = "http://localhost:5000/verify"
with open("foto.jpg", "rb") as f:
    files = {"image": f}
    response = requests.post(url, files=files)
    
result = response.json()
if result["is_me"]:
    print("‚úÖ Acceso autorizado")
else:
    print("‚ùå Acceso denegado")
```

### Ejemplo 3: Verificaci√≥n de Salud del Servidor

```python
import requests

# Verificar estado
response = requests.get("http://localhost:5000/healthz")
status = response.json()

if status["status"] == "ok":
    print("‚úÖ Servidor funcionando correctamente")
else:
    print(f"‚ùå Servidor con problemas: {status.get('reason', 'Desconocido')}")
```

### Ejemplo 4: Procesamiento por Lotes

```python
import requests
import os
from pathlib import Path

url = "http://localhost:5000/verify"
results = []

# Procesar m√∫ltiples im√°genes
image_dir = Path("imagenes")
for image_path in image_dir.glob("*.jpg"):
    with open(image_path, "rb") as f:
        files = {"image": f}
        response = requests.post(url, files=files)
        result = response.json()
        results.append({
            "file": image_path.name,
            "is_me": result.get("is_me", False),
            "score": result.get("score", 0)
        })

# Mostrar resultados
for r in results:
    print(f"{r['file']}: {'‚úÖ' if r['is_me'] else '‚ùå'} (score: {r['score']:.2%})")
```

## üîç Troubleshooting

### Problema: "No se detect√≥ un rostro en la imagen"

**Causas posibles:**
- La imagen no contiene una cara visible
- La cara es muy peque√±a o est√° muy oscura
- La imagen est√° borrosa o de baja calidad

**Soluciones:**
- Usa im√°genes con buena iluminaci√≥n y resoluci√≥n
- Aseg√∫rate de que la cara est√© claramente visible
- Prueba con diferentes √°ngulos de la cara

### Problema: "Modelos no encontrados"

**Causas:**
- No se ejecut√≥ el pipeline de entrenamiento completo
- Los modelos fueron eliminados o movidos

**Soluciones:**
```bash
# Verificar que los modelos existen
ls models/

# Si no existen, ejecutar el pipeline completo
python scripts/crop_faces.py
python scripts/embeddings.py
python train.py
```

### Problema: "CUDA out of memory"

**Causas:**
- GPU con poca memoria
- Batch size demasiado grande

**Soluciones:**
- Reducir el batch size en `scripts/embeddings.py` (l√≠nea 19)
- Usar CPU en lugar de GPU (autom√°tico si CUDA no est√° disponible)
- Procesar menos im√°genes a la vez

### Problema: API muy lenta

**Causas:**
- Ejecut√°ndose en CPU en lugar de GPU
- Im√°genes muy grandes

**Soluciones:**
- Verificar que CUDA est√© disponible: `python -c "import torch; print(torch.cuda.is_available())"`
- Reducir tama√±o de im√°genes antes de enviarlas
- Usar Gunicorn con m√∫ltiples workers en producci√≥n

### Problema: "Archivo demasiado grande"

**Causas:**
- Imagen excede el l√≠mite de `MAX_CONTENT_MB`

**Soluciones:**
- Reducir tama√±o de la imagen antes de enviarla
- Aumentar `MAX_CONTENT_MB` en `.env`

### Problema: Accuracy baja o modelo malo

**Causas:**
- Pocas im√°genes de entrenamiento
- Datos desbalanceados extremos
- Im√°genes de mala calidad

**Soluciones:**
- Aumentar el n√∫mero de im√°genes en `data/me/` y `data/not_me/`
- Asegurar al menos 30-50 im√°genes por categor√≠a
- Usar im√°genes de buena calidad y variadas (diferentes √°ngulos, iluminaci√≥n, etc.)
- Verificar las m√©tricas en `reports/metrics.json`

## üìä Estructura de la API

### Arquitectura Modular

La API est√° organizada en m√≥dulos para facilitar el mantenimiento:

```
api/
‚îú‚îÄ‚îÄ resources/          # Endpoints (Rutas)
‚îÇ   ‚îú‚îÄ‚îÄ verify.py       # Endpoint /verify
‚îÇ   ‚îî‚îÄ‚îÄ health.py       # Endpoint /healthz
‚îî‚îÄ‚îÄ utils/              # Utilidades
    ‚îú‚îÄ‚îÄ model_loader.py    # Carga de modelos (lazy loading)
    ‚îî‚îÄ‚îÄ image_processor.py # Procesamiento de im√°genes
```

### Flujo de Procesamiento en `/verify`

1. **Validaci√≥n**: Verifica que se envi√≥ una imagen v√°lida
2. **Detecci√≥n**: MTCNN detecta y recorta la cara
3. **Embedding**: FaceNet genera vector de caracter√≠sticas (512D)
4. **Escalado**: Aplica StandardScaler
5. **Clasificaci√≥n**: LogisticRegression predice probabilidad
6. **Umbral**: Compara con `VERIFY_THRESHOLD` para determinar `is_me`
7. **Respuesta**: Retorna resultado JSON

### Carga de Modelos

Los modelos se cargan **una sola vez al iniciar el servidor** (lazy loading):
- Primera petici√≥n: Carga los modelos
- Peticiones subsecuentes: Reutiliza modelos cargados en memoria
- Esto mejora significativamente el tiempo de respuesta

## üìà Evaluaci√≥n y Reportes

- **M√©tricas de entrenamiento**: `reports/metrics.json` (split 70/15/15, guardado por `train.py`).
- **Evaluaci√≥n 80/20 reproducible**: `evaluate.py` genera `reports/evaluation_results.json` y gr√°ficos (`confusion_matrix.png`, `roc_curve.png`, `pr_curve.png`).
- **Informe t√©cnico extendido**: `reports/INFORME_H10.md` resume dataset, pipeline, an√°lisis de umbral, m√©tricas, latencia y recomendaciones.
- **Umbral operativo**: configurable mediante `VERIFY_THRESHOLD` (default `0.75`). `evaluate.py` calcula el umbral √≥ptimo seg√∫n F1-score (`threshold_analysis.optimal_threshold_f1`).
- **Latencia de inferencia**: la regresi√≥n log√≠stica tarda ‚âà0.002‚ÄØms por muestra en CPU; los tiempos totales dependen de la detecci√≥n y del embedding.

Recomendaciones:
- Re-ejecutar `evaluate.py` tras cualquier cambio en el dataset o en el modelo.
- Documentar en `reports/` cualquier evaluaci√≥n manual adicional (p. ej., pruebas con datos externos).

## üõ°Ô∏è √âtica y Privacidad

- **Datos sensibles**: las im√°genes crudas contienen informaci√≥n biom√©trica. No se versionan; almac√©nalas cifradas y elimina copias temporales tras procesar.
- **Consentimiento**: aseg√∫rate de contar con autorizaci√≥n expl√≠cita de cada persona en `data/not_me`.
- **Uso responsable**: limita el acceso a la API y registra auditor√≠as de uso para detectar abuso.
- **Cumplimiento normativo**: considera GDPR/LGPD y leyes locales antes de desplegar en producci√≥n; ofrece mecanismos para revocar consentimiento y eliminar datos.
- **Sesgos**: el dataset actual est√° desbalanceado (‚âà10‚ÄØ% positivos). Ampl√≠a la cobertura con m√°s im√°genes propias y casos negativos diversos para reducir sesgos.

## üöÄ Despliegue en Producci√≥n

### Con Gunicorn

```bash
gunicorn -w 4 -b 0.0.0.0:5000 --timeout 120 app:app
```

**Par√°metros:**
- `-w 4`: 4 workers (ajustar seg√∫n CPU)
- `-b 0.0.0.0:5000`: Host y puerto
- `--timeout 120`: Timeout de 120 segundos (para procesamiento de im√°genes)

### Con Docker (Ejemplo)

```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY . .

CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "app:app"]
```

### Variables de Entorno en Producci√≥n

Aseg√∫rate de configurar:
```env
FLASK_DEBUG=False
VERIFY_THRESHOLD=0.75
MAX_CONTENT_MB=2
```

## üìö Referencias

- **FaceNet Paper**: [FaceNet: A Unified Embedding for Face Recognition and Clustering](https://arxiv.org/abs/1503.03832)
- **MTCNN**: [Joint Face Detection and Alignment using Multi-task Cascaded Convolutional Networks](https://arxiv.org/abs/1604.02878)
- **facenet-pytorch**: [GitHub Repository](https://github.com/timesler/facenet-pytorch)
- **Flask**: [Documentaci√≥n Oficial](https://flask.palletsprojects.com/)

## üìÑ Licencia

Este proyecto es de uso educativo/acad√©mico.

## üë§ Autor

Sistema de Reconocimiento Facial - Universidad

---

**¬øProblemas?** Revisa la secci√≥n [Troubleshooting](#troubleshooting) o abre un issue en el repositorio.

